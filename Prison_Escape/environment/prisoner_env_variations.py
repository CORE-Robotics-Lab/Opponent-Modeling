from Prison_Escape.environment.prisoner_perspective_envs import PrisonerEnv
from Prison_Escape.environment import PrisonerBothEnv, PrisonerBlueEnv, PrisonerEnv
from Prison_Escape.blue_policies.heuristic import BlueHeuristic
from Prison_Escape.fugitive_policies.heuristic import HeuristicPolicy
from Prison_Escape.fugitive_policies.rrt_star_adversarial_avoid import RRTStarAdversarialAvoid
import numpy as np
import random

""" This file contains the code to produce the environment we are using for the 3/15 review deadline

0: original map provided by sponsors. We are specifically training on maps_0.2/1.npy
1 - 4: These are maps generated by Perlin Noise

"""


def initialize_prisoner_environment(variation, camera_configuration="simulator/camera_locations/original_and_more.txt",
                                    observation_step_type="Fugitive",
                                    epsilon=0.0,
                                    random_cameras=False,
                                    seed=0,
                                    step_reset=True,
                                    num_random_known_cameras=25,
                                    num_random_unknown_cameras=25,
                                    terrain=None,
                                    store_last_k_fugitive_detections=False,
                                    heuristic_type="Normal",
                                    include_camera_at_start=False):  # RRT or Normal,
                                    
    print(f"Loaded environment variation {variation} with seed {seed}")

    # set seeds
    np.random.seed(seed)
    random.seed(seed)

    terrain_map = f'simulator/forest_coverage/map_set/{variation}.npy'
    if variation == 0:
        mountain_locations = [(400, 300), (1600, 1800)]  # original mountain setup
    elif variation == 1:
        mountain_locations = [(400, 2000), (1500, 1000)]
    elif variation == 2:
        mountain_locations = [(1000, 900), (1500, 1300)]
    elif variation == 3:
        mountain_locations = [(600, 1100), (1000, 1900)]
    else:
        raise ValueError(f'Invalid variation {variation}')

    env = PrisonerBothEnv(terrain=terrain,
                          spawn_mode='normal',
                          observation_step_type=observation_step_type,
                          random_cameras=random_cameras,
                          camera_file_path=camera_configuration,
                          mountain_locations=mountain_locations,
                          camera_range_factor=1.0,
                          observation_terrain_feature=False,
                          random_hideout_locations=False,
                          spawn_range=350,
                          helicopter_battery_life=200,
                          helicopter_recharge_time=40,
                          num_search_parties=5,
                          terrain_map=terrain_map,
                          step_reset=step_reset,
                          camera_net_bool=False,
                          num_random_known_cameras=num_random_known_cameras,
                          num_random_unknown_cameras=num_random_unknown_cameras,
                          store_last_k_fugitive_detections=store_last_k_fugitive_detections,
                          include_camera_at_start=include_camera_at_start
                          )

    env.seed(seed)
    # if observation_step_type == "Fugitive":
    #     blue_policy = BlueHeuristic(env, debug=False)
    #     env = PrisonerEnv(env, blue_policy)
    # elif observation_step_type == "Blue":
    #     if heuristic_type == "Normal":
    #         red_policy = HeuristicPolicy(env, epsilon=epsilon)
    #     elif heuristic_type == "RRT":
    #         red_policy = RRTStarAdversarialAvoid(env, max_speed=7.5, n_iter=2000)
    #     env = PrisonerBlueEnv(env, red_policy)

    return env


def intialize_multimodal_env(observation_step_type="Fugitive"):
    """ Return a tuple of two environments, this is to show multimodal behavior """

    terrain_map = f'simulator/forest_coverage/map_set/0.npy'
    mountain_locations = [(400, 300), (1600, 1800)]  # original mountain setup
    camera_configuration = "simulator/camera_locations/original_and_more.txt"
    terrain = None
    step_reset = True

    # known_hideout_locations = [[323, 1623], [1804, 737], [317, 2028], [819, 1615], [1145, 182], [1304, 624], [234, 171], [2398, 434], [633, 2136], [1590, 2]],
    # unknown_hideout_locations = [[376, 1190], [909, 510], [397, 798], [2059, 541], [2011, 103], [901, 883], [1077, 1445], [602, 372], [80, 2274], [279, 477]],

    seed = 0
    known_hideout_locations = [[323, 1623]]
    unknown_hideout_locations = [[80, 2274], [279, 477]]

    env_one = PrisonerEnv(terrain=terrain,
                          spawn_mode='normal',  # set position to be in the exact same place
                          observation_step_type=observation_step_type,
                          random_cameras=False,
                          camera_file_path=camera_configuration,
                          mountain_locations=mountain_locations,
                          camera_range_factor=1.0,
                          observation_terrain_feature=False,
                          random_hideout_locations=False,
                          spawn_range=350,
                          helicopter_battery_life=200,
                          helicopter_recharge_time=40,
                          num_search_parties=5,
                          terrain_map=terrain_map,
                          step_reset=step_reset,
                          known_hideout_locations=known_hideout_locations,
                          unknown_hideout_locations=unknown_hideout_locations
                          )
    env_one.seed(seed)

    known_hideout_locations = [[323, 1623]]
    unknown_hideout_locations = [[2011, 103], [279, 477]]

    env_two = PrisonerEnv(terrain=terrain,
                          spawn_mode='normal',
                          observation_step_type=observation_step_type,
                          random_cameras=False,
                          camera_file_path=camera_configuration,
                          mountain_locations=mountain_locations,
                          camera_range_factor=1.0,
                          observation_terrain_feature=False,
                          random_hideout_locations=False,
                          spawn_range=350,
                          helicopter_battery_life=200,
                          helicopter_recharge_time=40,
                          num_search_parties=5,
                          terrain_map=terrain_map,
                          step_reset=step_reset,
                          known_hideout_locations=known_hideout_locations,
                          unknown_hideout_locations=unknown_hideout_locations
                          )
    env_two.seed(seed)

    return env_one, env_two